{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import đồ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "dataset= pd.read_csv(\"C://Users//vutuan//Desktop//My-Projects//Machine Learning//Datasets//Medical-Cost-Personal-Datasets.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19 'female' 27.9 0 16884.924]\n",
      " [18 'male' 33.77 1 1725.5523]\n",
      " [28 'male' 33.0 3 4449.462]\n",
      " ...\n",
      " [18 'female' 36.85 0 1629.8335]\n",
      " [21 'female' 25.8 0 2007.945]\n",
      " [61 'female' 29.07 0 29141.3603]] [['yes']\n",
      " ['no']\n",
      " ['no']\n",
      " ...\n",
      " ['no']\n",
      " ['no']\n",
      " ['yes']]\n"
     ]
    }
   ],
   "source": [
    "#chọn feature\n",
    "X= dataset.iloc[:,[0,1,2,3,6]].values\n",
    "y= dataset.iloc[:,[4]].values\n",
    "\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.90000000e+01 0.00000000e+00 2.79000000e+01 0.00000000e+00\n",
      "  1.68849240e+04]\n",
      " [1.80000000e+01 1.00000000e+00 3.37700000e+01 1.00000000e+00\n",
      "  1.72555230e+03]\n",
      " [2.80000000e+01 1.00000000e+00 3.30000000e+01 3.00000000e+00\n",
      "  4.44946200e+03]\n",
      " ...\n",
      " [1.80000000e+01 0.00000000e+00 3.68500000e+01 0.00000000e+00\n",
      "  1.62983350e+03]\n",
      " [2.10000000e+01 0.00000000e+00 2.58000000e+01 0.00000000e+00\n",
      "  2.00794500e+03]\n",
      " [6.10000000e+01 0.00000000e+00 2.90700000e+01 0.00000000e+00\n",
      "  2.91413603e+04]]\n",
      "[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#encoding data\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "        if(X[i][j]=='female'):\n",
    "            X[i][j]=0.\n",
    "        if(X[i][j]=='male'):\n",
    "            X[i][j]=1.\n",
    "            \n",
    "for i in range(y.shape[0]):\n",
    "    for j in range(y.shape[1]):\n",
    "        if(y[i][j]=='no'):\n",
    "            y[i][j]=0\n",
    "        if(y[i][j]=='yes'):\n",
    "            y[i][j]=1\n",
    "            \n",
    "X = X.astype('float64')\n",
    "y = y.astype('float64')\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.30000000e+01 1.00000000e+00 3.52450000e+01 0.00000000e+00\n",
      "  1.24048791e+04]\n",
      " [4.60000000e+01 0.00000000e+00 2.77200000e+01 1.00000000e+00\n",
      "  8.23263880e+03]\n",
      " [1.90000000e+01 0.00000000e+00 2.89000000e+01 0.00000000e+00\n",
      "  1.74321400e+03]\n",
      " ...\n",
      " [5.70000000e+01 1.00000000e+00 2.37000000e+01 0.00000000e+00\n",
      "  1.09593300e+04]\n",
      " [2.50000000e+01 1.00000000e+00 2.62200000e+01 0.00000000e+00\n",
      "  2.72132080e+03]\n",
      " [1.80000000e+01 0.00000000e+00 3.82800000e+01 0.00000000e+00\n",
      "  1.41330377e+04]], shape=(536, 5), dtype=float64) [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#chia data thành train và test\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4,random_state=3)\n",
    "#chuyển thành mảng tensor\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "print(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cài đạt mạng neuron\n",
    "model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(5,)),\n",
    "        Dense(11, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "\n",
    "    ], \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chọn loss functin và optimizer\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 11)                66        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78\n",
      "Trainable params: 78\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#thông tin mạng neuron\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 1ms/step - loss: 1951.7333\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1753.9596\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1559.6055\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1357.6161\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1160.3219\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 964.7737\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 766.1711\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 547.7864\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 334.8395\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 124.2017\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2807\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 43.5335\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 41.8403\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 38.9337\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 37.3360\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 36.6861\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 35.9403\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 32.8116\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 32.4939\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 30.3230\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 29.6560\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 28.5847\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 27.5266\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 26.1076\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 997us/step - loss: 24.4254\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 23.3517\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 22.7887\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 21.4857\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 20.4066\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 18.5450\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 18.7603\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 997us/step - loss: 16.4849\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 15.8637\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 15.6800\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 14.9010\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 12.9510\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 997us/step - loss: 11.9054\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 10.0052\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 9.8119\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 8.1948\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 7.2357\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 6.5422\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 6.7975\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 5.2744\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 3.8155\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.7224\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 2.3358\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 987us/step - loss: 1.9999\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.5588\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.4377\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.8601\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.9875\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.8786\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 1.2939\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.7083\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4223\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4172\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3790\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3467\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5691\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3055\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4321\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6655\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4843\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4527\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3015\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4015\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3884\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4025\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3681\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5691\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2241\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2077\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.2050\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1792\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2412\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1968\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0856\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3315\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.8307\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2644\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2064\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3182\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.4400\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6743\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6672\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.6930\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3512\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2993\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2976\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2556\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5640\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2640\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3438\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1706\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1857\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.1947\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3545\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.2500\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.3168\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 686us/step\n",
      "số lỗi: 24\n",
      "chính xác: 512\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " ...\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_test)\n",
    "for i in range(pred.shape[0]):\n",
    "    for j in range(pred.shape[1]):\n",
    "        if(pred[i][j]>=0.5):\n",
    "            pred[i][j]=1\n",
    "        if(pred[i][j]<=0.5):\n",
    "            pred[i][j]=0\n",
    "y_hat=np.hstack((y_test,pred))\n",
    "err=0\n",
    "cor=0\n",
    "for i in range(y_hat.shape[0]):\n",
    "    if(y_hat[i][0]!=y_hat[i][1]):\n",
    "        err+=1\n",
    "    else:\n",
    "        cor+=1\n",
    "print('số lỗi:',err)\n",
    "print('chính xác:',cor)\n",
    "print(y_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
